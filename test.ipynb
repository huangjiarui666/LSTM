{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime as dt\n",
    "import time as time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#保证每次结果一致\n",
    "seed = 4444\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "import models\n",
    "import time\n",
    "from torch.utils.data import TensorDataset,Dataset,DataLoader,random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#导入数据\n",
    "df = pd.read_csv(\"data/ship/ship_motion.csv\")\n",
    "# 检查每一列是否包含空值\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "# 打印包含空值的列\n",
    "for column, count in null_counts.items():\n",
    "    if count > 0:\n",
    "        print(f\"列 '{column}' 有 {count} 个空值.\")\n",
    "    else:\n",
    "        print(\"未发现空值\")\n",
    "        break\n",
    "df.head()\n",
    "\n",
    "\n",
    "class config:\n",
    "    L = 6\n",
    "    H = 1\n",
    "    input_size = 3\n",
    "    hidden_size = 64\n",
    "    num_layers = 6\n",
    "    batch_size = 32\n",
    "    learning_rate = 0.001\n",
    "    out_channels = 9\n",
    "\n",
    "\n",
    "#滑动窗口函数\n",
    "def univariate_data(sequence, input_size, output_size, step):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for i in range(0, len(sequence) - input_size - output_size + 1, step):\n",
    "        inputs.append(sequence[i:i + input_size].reshape((1, input_size, 1)))\n",
    "        outputs.append(sequence[i + input_size:i + input_size + output_size])\n",
    "    return np.concatenate(inputs, axis=0), np.array(outputs)\n",
    "\n",
    "\n",
    "#训练输入\n",
    "train_x = df['Heave'].values.astype(np.float32)[:6096]  #选取标签列前4500个数据点作为训练数据\n",
    "norm_train_x = (train_x - np.min(train_x)) / (np.max(train_x) - np.min(train_x))  #归一化\n",
    "train_seq, train_label = univariate_data(norm_train_x, input_size=config.L, output_size=config.H, step=1)\n",
    "\n",
    "feature_columns = ['Heave', 'Pitch', 'Roll']\n",
    "trainX = []\n",
    "\n",
    "for column in feature_columns:\n",
    "    train_xx = df[column].values.astype(np.float32)[:6096]\n",
    "    norm_train_xx = (train_xx - np.min(train_xx)) / (np.max(train_xx) - np.min(train_xx))\n",
    "    train_seqx, _ = univariate_data(norm_train_xx, input_size=config.L, output_size=config.H, step=1)\n",
    "    trainX.append(train_seqx)\n",
    "\n",
    "# 合并特征作为输入\n",
    "trainX = np.concatenate(trainX, axis=2)\n",
    "\n",
    "#训练标签\n",
    "trainY = train_label\n",
    "\n",
    "#测试输入\n",
    "def preprocess_data(df, columns, input_size, output_size):\n",
    "    # 用于存储特征序列的列表\n",
    "    feature_seqs = []\n",
    "    for column in columns:\n",
    "        # 提取特征并归一化\n",
    "        feature = df[column].values.astype(np.float32)[6096:6222]\n",
    "        norm_feature = (feature - np.min(feature)) / (np.max(feature) - np.min(feature))\n",
    "        # 创建特征序列\n",
    "        feature_seq, _ = univariate_data(norm_feature, input_size=input_size, output_size=output_size, step=1)\n",
    "        feature_seqs.append(feature_seq)\n",
    "\n",
    "    # 合并特征序列\n",
    "    input_data = np.concatenate(feature_seqs, axis=2)\n",
    "\n",
    "    # 提取标签数据\n",
    "    test_x = df['Heave'].values.astype(np.float32)[6096:6222]\n",
    "    norm_label = (test_x - np.min(test_x)) / (np.max(test_x) - np.min(test_x))\n",
    "    text_seq, _ = univariate_data(norm_label, input_size=input_size, output_size=output_size, step=1)\n",
    "\n",
    "    return input_data, text_seq, test_x\n",
    "\n",
    "# 指定特征列和参数\n",
    "feature_columns = ['Heave','Pitch','Roll']\n",
    "input_size = config.L\n",
    "output_size = config.H\n",
    "\n",
    "# 调用函数进行数据预处理\n",
    "testX, testY, test_x = preprocess_data(df, feature_columns, input_size, output_size)\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size = config.input_size, hidden_size = 64, num_layers =2, batch_first = True)\n",
    "        self.linear = nn.Linear(64,config.H) #线性映射，从LSTM输出隐藏层维度为64，需要映射到H步长\n",
    "\n",
    "    def forward(self,x):\n",
    "        h_0 = torch.zeros(2, x.size(0), 64) #2指2个LSTM层，64指64个隐藏层\n",
    "        c_0 = torch.zeros(2, x.size(0), 64)\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        h_out = h_out[1]            #取最后一个LSTM层的输出[num_layers,B,hidden_size] -> [B,hidden_size]\n",
    "        out = self.linear(h_out)    #线性映射\n",
    "        return out\n",
    "\n",
    "# 训练训练训练训练训练训练\n",
    "X_train = torch.from_numpy(trainX)\n",
    "Y_train = torch.from_numpy(trainY)\n",
    "#dataloader\n",
    "seq_loader = DataLoader(X_train,batch_size=config.batch_size,drop_last=True)\n",
    "label_loader = DataLoader(Y_train,batch_size=config.batch_size,drop_last=True)\n",
    "\n",
    "model = LSTM()\n",
    "criterion = nn.MSELoss(reduction='mean')#定义损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "print(\"Training process initializing .....\\n\")\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for e in range(200):\n",
    "    total_loss = 0.\n",
    "    for seq,label in zip(seq_loader,label_loader):\n",
    "        #label = label.squeeze(2)若用最大最小归一化函数需要加这一句\n",
    "        output = model(seq)  #模型拟合,分批次输入进行拟合训练\n",
    "\n",
    "        optimizer.zero_grad()          #清空过往梯度\n",
    "        loss = criterion(output,label) #计算输出和真实值之间的损失\n",
    "        loss.backward()                #反向传播，计算当前梯度\n",
    "        optimizer.step()               #优化器更新\n",
    "        total_loss += loss             #累加损失\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        print('[Epoch {}] ,loss: {: .6f}'.format(e+1,total_loss))\n",
    "\n",
    "end = time.time()\n",
    "print(\"\\nFinish Training\")\n",
    "print(\"Training Time \", end - start)\n",
    "\n",
    "torch.save(model.state_dict(),\"Model_save/LSTM.pth\")#保存模型\n",
    "\n",
    "# 测试测试测试测试测试测试测试测试\n",
    "X_test = torch.from_numpy(testX)\n",
    "Y_test = torch.from_numpy(testY)\n",
    "\n",
    "#调用模型\n",
    "model.load_state_dict(torch.load(\"Model_save/LSTM.pth\"))\n",
    "model.eval()\n",
    "#生成预测值\n",
    "prediction = model(X_test)\n",
    "result = prediction.detach()\n",
    "\n",
    "result = result[:,0]\n",
    "forecast = (np.max(test_x)-np.min(test_x))*result+np.min(test_x)#反归一化\n",
    "\n",
    "#真实值\n",
    "Y_test0 = Y_test[:,0]\n",
    "original = (np.max(test_x)-np.min(test_x))*Y_test0+np.min(test_x)#反归一化\n",
    "\n",
    "# 评价指标评价指标评价指标评价指标\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "r2 = r2_score(original,forecast)\n",
    "print(r2)\n",
    "mae = mean_absolute_error(original,forecast)\n",
    "print(mae)\n",
    "mse = mean_squared_error(original,forecast)\n",
    "print(mse)\n",
    "rmse = mean_squared_error(original,forecast,squared=False)\n",
    "print(rmse)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
